{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1be1b2f55b62c0",
   "metadata": {},
   "source": [
    "# Food Classification with CNN - Building a Restaurant Recommendation System\n",
    "\n",
    "This assignment focuses on developing a deep learning-based food classification system using Convolutional Neural Networks (CNNs). You will build a model that can recognize different food categories and use it to return the food preferences of a user.\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement CNNs for image classification\n",
    "- Work with real-world food image datasets\n",
    "- Build a preference-detector system\n",
    "\n",
    "## Background: AI-Powered Food Preference Discovery\n",
    "\n",
    "The system's core idea is simple:\n",
    "\n",
    "1. Users upload 10 photos of dishes they enjoy\n",
    "2. Your CNN classifies these images into the 91 categories\n",
    "3. Based on these categories, the system returns the user's taste profile\n",
    "\n",
    "Your task is to develop the core computer vision component that will power this detection engine.\n",
    "\n",
    "You are given a training (\"train\" folder) and a test (\"test\" folder) dataset which have ~45k and ~22k samples respectively. For each one of the 91 classes there is a subdirectory containing the images of the respective class.\n",
    "\n",
    "## Assignment Requirements\n",
    "\n",
    "### Technical Requirements\n",
    "- Implement your own pytorch CNN architecture for food image classification\n",
    "- Use only the provided training dataset split for training\n",
    "- Train the network from scratch ; No pretrained weights can be used\n",
    "- Report test-accuracy after every epoch\n",
    "- Report all hyperparameters of final model\n",
    "- Use a fixed seed and do not use any CUDA-features that break reproducibility\n",
    "- Use Pytorch 2.6\n",
    "\n",
    "### Deliverables\n",
    "1. Jupyter Notebook with CNN implementation, training code etc.\n",
    "2. README file\n",
    "3. Report (max 3 pages)\n",
    "\n",
    "Submit your report, README and all code files as a single zip file named GROUP_[number]_NC2425_PA. The names and IDs of the group components must be mentioned in the README.\n",
    "Do not include the dataset in your submission.\n",
    "\n",
    "### Grading\n",
    "\n",
    "1. Correct CNN implementation, training runs on the uni DSLab computers according to the README.MD instructions without ANY exceptions on the DSLab machines: 3pt\n",
    "2. Perfect 1:1 reproducibility on DSLab machines: 1pt\n",
    "3. Very clear github-repo-style README.MD with instructions for running the code: 1pt\n",
    "4. Report: 1pt\n",
    "5. Model test performance on test-set: interpolated from 30-80% test-accuracy: 0-3pt\n",
    "6. Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt\n",
    "7. Bonus point: use an LLM (API) to generate short description / profile of preferences of the simulated user\n",
    "\n",
    "**If there is anything unclear about this assignment please post your question in the Brightspace discussions forum or send an email**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c222e5c4ff1b26",
   "metadata": {},
   "source": [
    "# Loading the datasets\n",
    "The dataset is already split into a train and test set in the directories \"train\" and \"test\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416f413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPER-PARAMETER SET-UP ###\n",
    "\n",
    "# Randomization\n",
    "random_seed = 42\n",
    "# Model training\n",
    "workers = 4\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "# Optimizer (Adam)\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0\n",
    "betas = (0.9, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e5a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS AND DEVICE SELECTION ###\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "from datetime import datetime as dt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Use the GPU to speed up the training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed23ce7b9cbfbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi']\n",
      "Class to index mapping: {'beet_salad': 0, 'beignets': 1, 'bibimbap': 2, 'bread_pudding': 3, 'breakfast_burrito': 4, 'bruschetta': 5, 'caesar_salad': 6, 'cannoli': 7, 'caprese_salad': 8, 'carrot_cake': 9, 'ceviche': 10, 'cheese_plate': 11, 'cheesecake': 12, 'chicken_curry': 13, 'chicken_quesadilla': 14, 'chicken_wings': 15, 'chocolate_cake': 16, 'chocolate_mousse': 17, 'churros': 18, 'clam_chowder': 19, 'club_sandwich': 20, 'crab_cakes': 21, 'creme_brulee': 22, 'croque_madame': 23, 'cup_cakes': 24, 'deviled_eggs': 25, 'donuts': 26, 'dumplings': 27, 'edamame': 28, 'eggs_benedict': 29, 'escargots': 30, 'falafel': 31, 'filet_mignon': 32, 'fish_and_chips': 33, 'foie_gras': 34, 'french_fries': 35, 'french_onion_soup': 36, 'french_toast': 37, 'fried_calamari': 38, 'fried_rice': 39, 'frozen_yogurt': 40, 'garlic_bread': 41, 'gnocchi': 42, 'greek_salad': 43, 'grilled_cheese_sandwich': 44, 'grilled_salmon': 45, 'guacamole': 46, 'gyoza': 47, 'hamburger': 48, 'hot_and_sour_soup': 49, 'hot_dog': 50, 'huevos_rancheros': 51, 'hummus': 52, 'ice_cream': 53, 'lasagna': 54, 'lobster_bisque': 55, 'lobster_roll_sandwich': 56, 'macaroni_and_cheese': 57, 'macarons': 58, 'miso_soup': 59, 'mussels': 60, 'nachos': 61, 'omelette': 62, 'onion_rings': 63, 'oysters': 64, 'pad_thai': 65, 'paella': 66, 'pancakes': 67, 'panna_cotta': 68, 'peking_duck': 69, 'pho': 70, 'pizza': 71, 'pork_chop': 72, 'poutine': 73, 'prime_rib': 74, 'pulled_pork_sandwich': 75, 'ramen': 76, 'ravioli': 77, 'red_velvet_cake': 78, 'risotto': 79, 'samosa': 80, 'sashimi': 81, 'scallops': 82, 'seaweed_salad': 83, 'shrimp_and_grits': 84, 'spaghetti_bolognese': 85, 'spaghetti_carbonara': 86, 'spring_rolls': 87, 'steak': 88, 'strawberry_shortcake': 89, 'sushi': 90}\n"
     ]
    }
   ],
   "source": [
    "### DATA LOADING ###\n",
    "\n",
    "# Allow repeatability\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed) \n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "# Define the transformer for the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # not all images are exactly 256x256\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "# Automatically download the dataset and associate folder names as labels\n",
    "train_dataset = datasets.ImageFolder(root='./train', transform=transform)  # No validation for now\n",
    "test_dataset = datasets.ImageFolder(root='./test', transform=transform)\n",
    "\n",
    "# Set up the data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False, num_workers=workers, pin_memory=True)\n",
    "\n",
    "# Make things easier to understand and utilize\n",
    "class_names = test_dataset.classes\n",
    "class_to_idx = test_dataset.class_to_idx\n",
    "num_classes = len(class_names)\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Class to index mapping:\", class_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bb30ae14ffa42",
   "metadata": {},
   "source": [
    "# CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4855a7fbfb90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NETWORK ARCHITECHTURE ####\n",
    "\n",
    "class FoodCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Start shape: 256x256x3\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=6, stride=2, padding=0)\n",
    "        # After Conv1: 126x126x32\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        # After Pool1: 42x42x32\n",
    "        self.conv2 = nn.Conv2d(32, 96, kernel_size=4, stride=2, padding=0)\n",
    "        # After Conv2: 20x20x96\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=6, stride=2)\n",
    "        # After Pool2: 8x8x96\n",
    "        self.conv3 = nn.Conv2d(96, 288, kernel_size=3, stride=1, padding=1)\n",
    "        # After Conv3: 8x8x288\n",
    "        self.conv4 = nn.Conv2d(288, 96, kernel_size=3, stride=1, padding=1)\n",
    "        # After Conv4: 8x8x96\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        # After Pool3: 6x6x96\n",
    "\n",
    "        # Flatten to: 3456 - Vector\n",
    "        self.fc6 = nn.Linear(96*6*6, 1536)\n",
    "        # After FCL1: 1536 - Vector\n",
    "        self.fc7 = nn.Linear(1536, 1536)\n",
    "        # After FCL2: 1536 - Vetor\n",
    "        self.fc8 = nn.Linear(1536, len(class_names))\n",
    "        # After FCL3: len(class_names) - Vector\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(F.relu(self.conv4(x)))\n",
    "        # Linearization\n",
    "        x = torch.flatten(x, 1)\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = self.fc8(x)\n",
    "       \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c602d154e795a27",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "Implement your training process below. Report the test-accuracy after every epoch for the training run of the final model.\n",
    "\n",
    "Hint: before training your model make sure to reset the seed in the training cell, as otherwise the seed may have changed due to previous training runs in the notebook\n",
    "\n",
    "Note: If you implement automatic hyperparameter tuning, split the train set into train and validation subsets for the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff7d9d84c06f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HELPER FUNCTIONS ###\n",
    "\n",
    "def calculate_test_accuracy(model):\n",
    "    \"\"\"Calculate the accuracy of a provided model using the global test_loader\"\"\"\n",
    "    # Evaulate using testing\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    # Don't calculate gradients to speed-up computation\n",
    "    with torch.no_grad():\n",
    "        for total, (images, labels) in enumerate(test_loader, start=1):\n",
    "            # Move the data to the computation device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Predict using the model\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Safe keep the results to return as a percentage\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return (correct/total) * 100\n",
    "\n",
    "\n",
    "def train(model, loss_fn, optimizer):\n",
    "    \"\"\"Trains a model using the global train_loader\"\"\"\n",
    "    # model.train(True)\n",
    "    for images, labels in train_loader:\n",
    "        # Move the data to the computation device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde65578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 begin: 2025-04-30 17:10:39.714730.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m start = time()\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mCompleted training after \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[33m seconds.\u001b[39m\u001b[33m'\u001b[39m.format((time() - start)))\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Output an update\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, loss_fn, optimizer)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Trains a model using the global train_loader\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# model.train(True)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Move the data to the computation device\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laith\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laith\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laith\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1445\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laith\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laith\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\queue.py:213\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laith\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "### TRAINING BLOCK ###\n",
    "\n",
    "# Allow repeatability\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed) \n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "# Create model object and connect it to the corresponding processing\n",
    "model = FoodCNN()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay, betas=betas)\n",
    "\n",
    "# Begin training, still includes developmental sections\n",
    "best_vloss = np.inf\n",
    "for epoch in range(num_epochs):\n",
    "\t# Start epoch\n",
    "    print(f\"Epoch {epoch+1} begin: {dt.now()}.\")\n",
    "    start = time()\n",
    "    \n",
    "    # Train the model\n",
    "    loss = train(model, loss_fn, optimizer)\n",
    "    print('Completed training after {:.2f} seconds.'.format((time() - start)))\n",
    "    \n",
    "    # Output an update\n",
    "    print('Total epoch time: {:.2f} seconds.'.format((time() - start)))\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "    print(\"####################################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrite? \"Yes\" / else: \n",
      "Original unchanged, Backup overwritten.\n"
     ]
    }
   ],
   "source": [
    "### MODEL SAVING ###\n",
    "print(\"Overwrite? \\\"Yes\\\" / else: \")\n",
    "user_input = input().lower()\n",
    "if user_input == \"yes\" or user_input == 'y':\n",
    "    PATH = './cnn.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"Save complete.\")\n",
    "else:\n",
    "    PATH = './cnn_backup.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"Original unchanged, Backup overwritten.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb476e18bd30968c",
   "metadata": {},
   "source": [
    "# Calculating model performance\n",
    "Load the best version of your model ( which should be produced and saved by previous cells ), calculate and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa35096547d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 15.13%\n"
     ]
    }
   ],
   "source": [
    "### MODEL COMPARISONS ###\n",
    "\n",
    "# # Load the best model weights\n",
    "# model2 = FoodCNN().to(device)\n",
    "# model2.load_state_dict(torch.load(\"cnn.pth\", weights_only=True))\n",
    "\n",
    "# Calculate and present final scores\n",
    "final_test_acc = calculate_test_accuracy(model)\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecc6f7f921591e",
   "metadata": {},
   "source": [
    "# Summary of hyperparameters\n",
    "Report the hyperparameters ( learning rate etc ) that you used in your final model for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6a524e28b431a",
   "metadata": {},
   "source": [
    "# Simulation of random user\n",
    "Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e8175cacc8dfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T17:04:06.539916Z",
     "start_time": "2025-04-02T17:04:05.929092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Below an example showing the format of the code output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7a3634bf6861f",
   "metadata": {},
   "source": [
    "# Bonus point\n",
    "Use an LLM (API) to generate a description of the food preference of a user based on 10 images that a potential user could provide. \n",
    "Please include an example of the output of your code, especially if you used an API other than the OpenAI API.\n",
    "\n",
    "This should work well even with differing test images by setting different random seeds for the image selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819fa0042485dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
