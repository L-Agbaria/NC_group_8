{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1be1b2f55b62c0",
   "metadata": {},
   "source": [
    "# Food Classification with CNN - Building a Restaurant Recommendation System\n",
    "\n",
    "This assignment focuses on developing a deep learning-based food classification system using Convolutional Neural Networks (CNNs). You will build a model that can recognize different food categories and use it to return the food preferences of a user.\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement CNNs for image classification\n",
    "- Work with real-world food image datasets\n",
    "- Build a preference-detector system\n",
    "\n",
    "## Background: AI-Powered Food Preference Discovery\n",
    "\n",
    "The system's core idea is simple:\n",
    "\n",
    "1. Users upload 10 photos of dishes they enjoy\n",
    "2. Your CNN classifies these images into the 91 categories\n",
    "3. Based on these categories, the system returns the user's taste profile\n",
    "\n",
    "Your task is to develop the core computer vision component that will power this detection engine.\n",
    "\n",
    "You are given a training (\"train\" folder) and a test (\"test\" folder) dataset which have ~45k and ~22k samples respectively. For each one of the 91 classes there is a subdirectory containing the images of the respective class.\n",
    "\n",
    "## Assignment Requirements\n",
    "\n",
    "### Technical Requirements\n",
    "- Implement your own pytorch CNN architecture for food image classification\n",
    "- Use only the provided training dataset split for training\n",
    "- Train the network from scratch ; No pretrained weights can be used\n",
    "- Report test-accuracy after every epoch\n",
    "- Report all hyperparameters of final model\n",
    "- Use a fixed seed and do not use any CUDA-features that break reproducibility\n",
    "- Use Pytorch 2.6\n",
    "\n",
    "### Deliverables\n",
    "1. Jupyter Notebook with CNN implementation, training code etc.\n",
    "2. README file\n",
    "3. Report (max 3 pages)\n",
    "\n",
    "Submit your report, README and all code files as a single zip file named GROUP_[number]_NC2425_PA. The names and IDs of the group components must be mentioned in the README.\n",
    "Do not include the dataset in your submission.\n",
    "\n",
    "### Grading\n",
    "\n",
    "1. Correct CNN implementation, training runs on the uni DSLab computers according to the README.MD instructions without ANY exceptions on the DSLab machines: 3pt\n",
    "2. Perfect 1:1 reproducibility on DSLab machines: 1pt\n",
    "3. Very clear github-repo-style README.MD with instructions for running the code: 1pt\n",
    "4. Report: 1pt\n",
    "5. Model test performance on test-set: interpolated from 30-80% test-accuracy: 0-3pt\n",
    "6. Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt\n",
    "7. Bonus point: use an LLM (API) to generate short description / profile of preferences of the simulated user\n",
    "\n",
    "**If there is anything unclear about this assignment please post your question in the Brightspace discussions forum or send an email**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c222e5c4ff1b26",
   "metadata": {},
   "source": [
    "# Loading the datasets\n",
    "The dataset is already split into a train and test set in the directories \"train\" and \"test\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed23ce7b9cbfbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi']\n",
      "Class to index mapping: {'beet_salad': 0, 'beignets': 1, 'bibimbap': 2, 'bread_pudding': 3, 'breakfast_burrito': 4, 'bruschetta': 5, 'caesar_salad': 6, 'cannoli': 7, 'caprese_salad': 8, 'carrot_cake': 9, 'ceviche': 10, 'cheese_plate': 11, 'cheesecake': 12, 'chicken_curry': 13, 'chicken_quesadilla': 14, 'chicken_wings': 15, 'chocolate_cake': 16, 'chocolate_mousse': 17, 'churros': 18, 'clam_chowder': 19, 'club_sandwich': 20, 'crab_cakes': 21, 'creme_brulee': 22, 'croque_madame': 23, 'cup_cakes': 24, 'deviled_eggs': 25, 'donuts': 26, 'dumplings': 27, 'edamame': 28, 'eggs_benedict': 29, 'escargots': 30, 'falafel': 31, 'filet_mignon': 32, 'fish_and_chips': 33, 'foie_gras': 34, 'french_fries': 35, 'french_onion_soup': 36, 'french_toast': 37, 'fried_calamari': 38, 'fried_rice': 39, 'frozen_yogurt': 40, 'garlic_bread': 41, 'gnocchi': 42, 'greek_salad': 43, 'grilled_cheese_sandwich': 44, 'grilled_salmon': 45, 'guacamole': 46, 'gyoza': 47, 'hamburger': 48, 'hot_and_sour_soup': 49, 'hot_dog': 50, 'huevos_rancheros': 51, 'hummus': 52, 'ice_cream': 53, 'lasagna': 54, 'lobster_bisque': 55, 'lobster_roll_sandwich': 56, 'macaroni_and_cheese': 57, 'macarons': 58, 'miso_soup': 59, 'mussels': 60, 'nachos': 61, 'omelette': 62, 'onion_rings': 63, 'oysters': 64, 'pad_thai': 65, 'paella': 66, 'pancakes': 67, 'panna_cotta': 68, 'peking_duck': 69, 'pho': 70, 'pizza': 71, 'pork_chop': 72, 'poutine': 73, 'prime_rib': 74, 'pulled_pork_sandwich': 75, 'ramen': 76, 'ravioli': 77, 'red_velvet_cake': 78, 'risotto': 79, 'samosa': 80, 'sashimi': 81, 'scallops': 82, 'seaweed_salad': 83, 'shrimp_and_grits': 84, 'spaghetti_bolognese': 85, 'spaghetti_carbonara': 86, 'spring_rolls': 87, 'steak': 88, 'strawberry_shortcake': 89, 'sushi': 90}\n",
      "Labels: tensor([42, 50, 88, 81, 81, 56, 61, 17,  2, 48, 38, 18, 44, 43, 14, 15, 21, 83,\n",
      "        64, 86,  0, 70, 55, 19, 52, 56, 42, 70, 32, 14, 76, 51])\n",
      "Labels as class names: ['gnocchi', 'hot_dog', 'steak', 'sashimi', 'sashimi', 'lobster_roll_sandwich', 'nachos', 'chocolate_mousse', 'bibimbap', 'hamburger', 'fried_calamari', 'churros', 'grilled_cheese_sandwich', 'greek_salad', 'chicken_quesadilla', 'chicken_wings', 'crab_cakes', 'seaweed_salad', 'oysters', 'spaghetti_carbonara', 'beet_salad', 'pho', 'lobster_bisque', 'clam_chowder', 'hummus', 'lobster_roll_sandwich', 'gnocchi', 'pho', 'filet_mignon', 'chicken_quesadilla', 'ramen', 'huevos_rancheros']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed) \n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # not all images are exactly 256x256\n",
    "    transforms.ToTensor(),     \n",
    "\n",
    "    # TO DO: understand/explain why these parameters are suggested\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "# Automatically download the dataset and associate folder names as labels\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "print(\"Class to index mapping:\", class_to_idx)\n",
    "\n",
    "# Create a DataLoader for the subset\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=16)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True, num_workers=16)\n",
    "\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(\"Labels:\", labels)  # Print the labels for the batch\n",
    "    print(\"Labels as class names:\", [class_names[label] for label in labels])  # Convert labels to class names\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bb30ae14ffa42",
   "metadata": {},
   "source": [
    "# CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4855a7fbfb90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FoodCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Start: 256x256x3\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=6, stride=2)\n",
    "        # After Conv1: 126x126x32\n",
    "        # MaxPool2d(3, 3): 42x42x32\n",
    "        self.conv2 = nn.Conv2d(32, 76, kernel_size=5)\n",
    "        # After Conv2: \n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3)\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, len(class_names))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.max_pool(F.relu(self.conv1(x)))\n",
    "        x = self.max_pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.max_pool(F.relu(self.conv5(x)))\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "       \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c602d154e795a27",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "Implement your training process below. Report the test-accuracy after every epoch for the training run of the final model.\n",
    "\n",
    "Hint: before training your model make sure to reset the seed in the training cell, as otherwise the seed may have changed due to previous training runs in the notebook\n",
    "\n",
    "Note: If you implement automatic hyperparameter tuning, split the train set into train and validation subsets for the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff7d9d84c06f5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 begin: 2025-04-29 18:39:10.786897.\n",
      "Took 56.61 seconds.\n",
      "Epoch [1/20], Loss: 4.5212, Accuracy: 1.05%\n",
      "Epoch 2 begin: 2025-04-29 18:40:07.399797.\n",
      "Took 56.13 seconds.\n",
      "Epoch [2/20], Loss: 4.5107, Accuracy: 0.97%\n",
      "Epoch 3 begin: 2025-04-29 18:41:03.532948.\n",
      "Took 56.84 seconds.\n",
      "Epoch [3/20], Loss: 4.5136, Accuracy: 0.97%\n",
      "Epoch 4 begin: 2025-04-29 18:42:00.377389.\n",
      "Took 57.04 seconds.\n",
      "Epoch [4/20], Loss: 4.5199, Accuracy: 0.95%\n",
      "Epoch 5 begin: 2025-04-29 18:42:57.418279.\n",
      "Took 56.81 seconds.\n",
      "Epoch [5/20], Loss: 4.5047, Accuracy: 0.95%\n",
      "Epoch 6 begin: 2025-04-29 18:43:54.230396.\n",
      "Took 57.13 seconds.\n",
      "Epoch [6/20], Loss: 4.5108, Accuracy: 0.95%\n",
      "Epoch 7 begin: 2025-04-29 18:44:51.362373.\n",
      "Took 56.89 seconds.\n",
      "Epoch [7/20], Loss: 4.5181, Accuracy: 0.95%\n",
      "Epoch 8 begin: 2025-04-29 18:45:48.255769.\n",
      "Took 56.73 seconds.\n",
      "Epoch [8/20], Loss: 4.5053, Accuracy: 0.96%\n",
      "Epoch 9 begin: 2025-04-29 18:46:44.984624.\n",
      "Took 56.91 seconds.\n",
      "Epoch [9/20], Loss: 4.5082, Accuracy: 0.96%\n",
      "Epoch 10 begin: 2025-04-29 18:47:41.896730.\n",
      "Took 56.98 seconds.\n",
      "Epoch [10/20], Loss: 4.5131, Accuracy: 0.96%\n",
      "Epoch 11 begin: 2025-04-29 18:48:38.880719.\n",
      "Took 56.78 seconds.\n",
      "Epoch [11/20], Loss: 4.5139, Accuracy: 0.96%\n",
      "Epoch 12 begin: 2025-04-29 18:49:35.662547.\n",
      "Took 56.91 seconds.\n",
      "Epoch [12/20], Loss: 4.5135, Accuracy: 0.96%\n",
      "Epoch 13 begin: 2025-04-29 18:50:32.574166.\n",
      "Took 56.82 seconds.\n",
      "Epoch [13/20], Loss: 4.5082, Accuracy: 0.95%\n",
      "Epoch 14 begin: 2025-04-29 18:51:29.398014.\n",
      "Took 56.61 seconds.\n",
      "Epoch [14/20], Loss: 4.5118, Accuracy: 0.95%\n",
      "Epoch 15 begin: 2025-04-29 18:52:26.004621.\n",
      "Took 56.96 seconds.\n",
      "Epoch [15/20], Loss: 4.5130, Accuracy: 0.96%\n",
      "Epoch 16 begin: 2025-04-29 18:53:22.969169.\n",
      "Took 56.79 seconds.\n",
      "Epoch [16/20], Loss: 4.5155, Accuracy: 0.95%\n",
      "Epoch 17 begin: 2025-04-29 18:54:19.759756.\n",
      "Took 56.79 seconds.\n",
      "Epoch [17/20], Loss: 4.5155, Accuracy: 0.95%\n",
      "Epoch 18 begin: 2025-04-29 18:55:16.548740.\n",
      "Took 57.20 seconds.\n",
      "Epoch [18/20], Loss: 4.5070, Accuracy: 0.95%\n",
      "Epoch 19 begin: 2025-04-29 18:56:13.749345.\n",
      "Took 56.77 seconds.\n",
      "Epoch [19/20], Loss: 4.5122, Accuracy: 0.95%\n",
      "Epoch 20 begin: 2025-04-29 18:57:10.516107.\n",
      "Took 57.42 seconds.\n",
      "Epoch [20/20], Loss: 4.5126, Accuracy: 0.95%\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "\n",
    "def calculate_test_accuracy(model):\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return (correct/total) * 100\n",
    "\n",
    "\n",
    "# Set the variables for training\n",
    "batch_size = 32\n",
    "num_classes = len(class_names)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "# Train and validate the CNN model\n",
    "model = FoodCNN().to(device)\n",
    "# print(model)\n",
    "\n",
    "# Set Loss function --- SOLUTION\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "# Set optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #??? , weight_decay = 0.005, momentum = 0.9) # Define the optimizer\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\t#Load data in batches\n",
    "    print(f\"Epoch {epoch+1} begin: {dt.datetime.now()}.\")\n",
    "    start = time.time()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    acc = calculate_test_accuracy(model)\n",
    "    print(\"Took {:.2f} seconds.\".format((time.time() - start)))\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, num_epochs, loss.item(), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad34673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrite? \"Yes\" / else: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverwrite? \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m / else: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_input \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m user_input \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      4\u001b[0m     PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./cnn.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "print(\"Overwrite? \\\"Yes\\\" / else: \")\n",
    "user_input = input().lower()\n",
    "if user_input == \"yes\" or user_input == 'y':\n",
    "    PATH = './cnn.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"Save complete.\")\n",
    "else:\n",
    "    PATH = './cnn_backup.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"Original unchanged, Backup overwritten.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb476e18bd30968c",
   "metadata": {},
   "source": [
    "# Calculating model performance\n",
    "Load the best version of your model ( which should be produced and saved by previous cells ), calculate and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa35096547d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model weights\n",
    "model2 = FoodCNN().to(device)\n",
    "model2.load_state_dict(torch.load(\"cnn_backup.pth\"))\n",
    "\n",
    "final_test_acc = calculate_test_accuracy(model2)\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecc6f7f921591e",
   "metadata": {},
   "source": [
    "# Summary of hyperparameters\n",
    "Report the hyperparameters ( learning rate etc ) that you used in your final model for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6a524e28b431a",
   "metadata": {},
   "source": [
    "# Simulation of random user\n",
    "Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e8175cacc8dfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T17:04:06.539916Z",
     "start_time": "2025-04-02T17:04:05.929092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Below an example showing the format of the code output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7a3634bf6861f",
   "metadata": {},
   "source": [
    "# Bonus point\n",
    "Use an LLM (API) to generate a description of the food preference of a user based on 10 images that a potential user could provide. \n",
    "Please include an example of the output of your code, especially if you used an API other than the OpenAI API.\n",
    "\n",
    "This should work well even with differing test images by setting different random seeds for the image selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819fa0042485dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
